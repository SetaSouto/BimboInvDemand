{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grupo Bimbo Inventory Demand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook con la implementación del modelo para [esta](https://www.kaggle.com/c/grupo-bimbo-inventory-demand) competencia en kaggle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas principales\n",
    "\n",
    "* Ocupar redes neuronales con la librería tensorflow.\n",
    "* Ocupar procesos guassianos con librería por seleccionar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Archivos\n",
    "\n",
    "* train.csv — the training set\n",
    "* test.csv — the test set\n",
    "* sample_submission.csv — a sample submission file in the correct format\n",
    "* cliente_tabla.csv — client names (can be joined with train/test on Cliente_ID)\n",
    "* producto_tabla.csv — product names (can be joined with train/test on Producto_ID)\n",
    "* town_state.csv — town and state (can be joined with train/test on Agencia_ID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features\n",
    "\n",
    "* Semana — Week number (From Thursday to Wednesday)\n",
    "* Agencia_ID — Sales Depot ID\n",
    "* Canal_ID — Sales Channel ID\n",
    "* Ruta_SAK — Route ID (Several routes = Sales Depot)\n",
    "* Cliente_ID — Client ID\n",
    "* NombreCliente — Client name\n",
    "* Producto_ID — Product ID\n",
    "* NombreProducto — Product Name\n",
    "* Venta_uni_hoy — Sales unit this week (integer)\n",
    "* Venta_hoy — Sales this week (unit: pesos)\n",
    "* Dev_uni_proxima — Returns unit next week (integer)\n",
    "* Dev_proxima — Returns next week (unit: pesos)\n",
    "* Demanda_uni_equil — Adjusted Demand (integer) (This is the target you will predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero importamos las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos una función para leer los datos. Retorna un dataFrame (pandas) de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fileName: Name of the csv file.\n",
    "# Columns: Array with the strings of each column in order.\n",
    "# rows: Number of rows to be read. None = All.\n",
    "def readData(fileName, columns, rows=None):\n",
    "    print('Reading file:', fileName)\n",
    "    start = time.time()\n",
    "    ret = pd.read_csv(fileName, usecols=columns, nrows=rows)\n",
    "    finish = time.time()\n",
    "    print('Shape:', str(ret.shape))\n",
    "    print('Execution time (seconds):', str(finish-start))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA:** Importar una columna completa del archivo train demora aproximadamente 1 minuto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: Archivos/train.csv\n",
      "Shape: (1000000, 7)\n",
      "Execution time (seconds): 0.7414398193359375\n"
     ]
    }
   ],
   "source": [
    "# How many rows we'll load\n",
    "total_loaded = 1000000\n",
    "\n",
    "# Import the dataset\n",
    "columns = ['Semana', 'Agencia_ID', 'Canal_ID', 'Ruta_SAK', 'Cliente_ID', 'Producto_ID', 'Demanda_uni_equil']\n",
    "dataset = readData('Archivos/train.csv', columns, rows=total_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Inspeccionemos los datos primero antes de generar cualquier modelo.  \n",
    "Nuestro valor objetivo es la última columna de nuestros datos: *Demanda_uni_equil*, veamos como se distribuye sobre los datos que hemos tomado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recieves an array of elements and plot its histogram\n",
    "# array: Values\n",
    "# maxValue: Max value to be shown in the histogram\n",
    "def toHist(array, maxValue, title='', xlabel='', ylabel=''):\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.hist(array[array<maxValue], bins=200, color='blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZwAAAEZCAYAAACjPJNSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4YRjZmZZOOGYmVkW/x9P5dcFkB7NwQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff251f0dc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "demanda_uni_equil = dataset['Demanda_uni_equil']\n",
    "toHist(demanda_uni_equil, 20, 'Histogram of Demanda_uni_equil', 'Value', 'Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Función para poder agrupar los valores de un dataFrame de acuerdo a los valores de cierta columna. Nos retorna una tupla con todos los valores distintos de la columna y un diccionario donde la llave es el valor y retorna un dataFrame con todas las filas con ese valor en la columna específica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Recieves a dataFrame and a column name (string) and returns a tuple \n",
    "# with the keys and a dict\n",
    "# where the key is de column value and the value is a dataFrame with all\n",
    "# the rows that have that column value.\n",
    "def groupBy(dataFrame, columnName):\n",
    "    different_values = dataFrame[columnName].drop_duplicates()\n",
    "    dictionary = dict()\n",
    "    for value in different_values:\n",
    "        # Select the data that have value in the columnName field.\n",
    "        data = dataFrame.loc[dataFrame[columnName]==value]\n",
    "        dictionary[value] = data\n",
    "    return (different_values, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función anterior se usaba, ya no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Modelamiento con NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A priori, haremos que la red reciba como input las 7 características que entrega el archivo test. Ocuparemos la función de error del programa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset (30000, 6)\n",
      "      outputs (30000,)\n",
      "Valid dataset (10000, 6)\n",
      "      outputs (10000,)\n",
      "Test  dataset (10000, 6)\n",
      "      outputs (10000,)\n"
     ]
    }
   ],
   "source": [
    "# The data is divided (seudo)randomnly in 3 groups: train_dataset, valid_dataset, and test_dataset.\n",
    "\n",
    "train_size = 30000\n",
    "valid_size = 10000\n",
    "test_size = 10000\n",
    "\n",
    "#-------------------------------------------------------\n",
    "# TODO: Hacer que las características que no tienen un orden (todas menos semana) sean one hot encoding.\n",
    "#-------------------------------------------------------\n",
    "\n",
    "# 6 feautres + output\n",
    "train = dataset.sample(train_size)\n",
    "valid = dataset.sample(valid_size)\n",
    "test = dataset.sample(test_size)\n",
    "\n",
    "# 6 features only, now they are numpy arrays\n",
    "train_dataset = train.drop('Demanda_uni_equil', axis=1).as_matrix().astype('float32')\n",
    "valid_dataset = valid.drop('Demanda_uni_equil', axis=1).as_matrix()\n",
    "test_dataset = test.drop('Demanda_uni_equil', axis=1).as_matrix()\n",
    "\n",
    "# Outputs\n",
    "train_output = train['Demanda_uni_equil'].as_matrix()\n",
    "valid_output = valid['Demanda_uni_equil'].as_matrix()\n",
    "test_output = test['Demanda_uni_equil'].as_matrix()\n",
    "\n",
    "print('Train dataset', train_dataset.shape)\n",
    "print('      outputs', train_output.shape)\n",
    "print('Valid dataset', valid_dataset.shape)\n",
    "print('      outputs', valid_output.shape)\n",
    "print('Test  dataset', test_dataset.shape)\n",
    "print('      outputs', test_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DataType int64 for attr 'T' not in list of allowed values: float32, float64, int32, complex64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ac71c271ee40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mtrain_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     valid_prediction = tf.nn.softmax( tf.matmul(\n\u001b[1;32m---> 63\u001b[1;33m         tf.nn.relu( tf.matmul(tf_valid_dataset, weights1) + biases1 ) , weights2)\n\u001b[0m\u001b[0;32m     64\u001b[0m                                      + biases2)\n\u001b[0;32m     65\u001b[0m     test_prediction = tf.nn.softmax( tf.matmul(\n",
      "\u001b[1;32m/home/fabian/anaconda3/envs/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[0;32m   1034\u001b[0m                                    \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                    \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m                                    name=name)\n\u001b[0m\u001b[0;32m   1037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m \u001b[0msparse_matmul\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_mat_mul\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/fabian/anaconda3/envs/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36m_mat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \"\"\"\n\u001b[0;32m    910\u001b[0m   return _op_def_lib.apply_op(\"MatMul\", a=a, b=b, transpose_a=transpose_a,\n\u001b[1;32m--> 911\u001b[1;33m                               transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/fabian/anaconda3/envs/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    484\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mbase_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbase_types\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m               _SatisfiesTypeConstraint(base_type,\n\u001b[1;32m--> 486\u001b[1;33m                                        _Attr(op_def, input_arg.type_attr))\n\u001b[0m\u001b[0;32m    487\u001b[0m             \u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m             \u001b[0minferred_from\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/fabian/anaconda3/envs/tensorflow/lib/python3.4/site-packages/tensorflow/python/ops/op_def_library.py\u001b[0m in \u001b[0;36m_SatisfiesTypeConstraint\u001b[1;34m(dtype, attr_def)\u001b[0m\n\u001b[0;32m     57\u001b[0m           \u001b[1;34m\"DataType %s for attr '%s' not in list of allowed values: %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m           (dtypes.as_dtype(dtype).name, attr_def.name,\n\u001b[1;32m---> 59\u001b[1;33m            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: DataType int64 for attr 'T' not in list of allowed values: float32, float64, int32, complex64"
     ]
    }
   ],
   "source": [
    "# Model deep neural network with stochastic gradient descent for speed.\n",
    "\n",
    "# How many features we want to use\n",
    "features = 6\n",
    "# Size of the placeholder in the train input data.\n",
    "batch_size = 512\n",
    "hidden_nodes = 1024\n",
    "beta = 0.001\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    \n",
    "    # Input data. For the training data, we use a placeholder that will be fed\n",
    "    # at run time with a training minibatch.\n",
    "    tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, features))\n",
    "    # We only have one output, the prediction.\n",
    "    tf_train_outputs = tf.placeholder(tf.float32, shape=(batch_size, 1))\n",
    "    # The valid dataset and the test dataset remain as constants.\n",
    "    tf_valid_dataset = tf.constant(valid_dataset)\n",
    "    tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "    #------------\n",
    "    # Variables:\n",
    "    #------------\n",
    "    \n",
    "    # First layer\n",
    "    weights1 = tf.Variable(\n",
    "        tf.truncated_normal([features, hidden_nodes]))\n",
    "    biases1 = tf.Variable(tf.zeros([hidden_nodes]))\n",
    "    \n",
    "    # Hidden layer\n",
    "    weights2 = tf.Variable(\n",
    "        tf.truncated_normal([hidden_nodes, 1]))\n",
    "    biases2 = tf.Variable(tf.zeros([1]))\n",
    "    \n",
    "    #----------------------\n",
    "    # Training computation.\n",
    "    #----------------------\n",
    "    \n",
    "    # Outputs after the first layer:\n",
    "    # We are using RELU, thats the non linearity in our model\n",
    "    outputs1 = tf.nn.relu( tf.matmul(tf_train_dataset, weights1) + biases1 )\n",
    "    \n",
    "    # Output after the second layer:\n",
    "    output = tf.matmul(outputs1, weights2) + biases2\n",
    "    \n",
    "    #-------\n",
    "    # Loss\n",
    "    #-------\n",
    "    loss = tf.sqrt( tf.reduce_mean( tf.square(tf.log(output+1) - tf.log(tf_train_outputs+1)) )) #+beta*tf.l2_loss(weights1) + tf.nn.l2_loss(weights2)\n",
    "    \n",
    "    #-----------\n",
    "    # Optimizer\n",
    "    #-----------\n",
    "  \n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = tf.nn.softmax(output)\n",
    "    valid_prediction = tf.nn.softmax( tf.matmul(\n",
    "        tf.nn.relu( tf.matmul(tf_valid_dataset, weights1) + biases1 ) , weights2)\n",
    "                                     + biases2)\n",
    "    test_prediction = tf.nn.softmax( tf.matmul(\n",
    "        tf.nn.relu( tf.matmul(tf_test_dataset, weights1) + biases1 ) , weights2) + biases2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
